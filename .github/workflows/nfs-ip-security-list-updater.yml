name: Update TrueNAS NFS Client IPs

on:
  workflow_dispatch:
  schedule:
    - cron: '*/15 * * * *'  # every 15 minutes

concurrency:
  group: nfs-ip-security-list-updater
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  update-nfs-clients:
    runs-on: ubuntu-latest
    timeout-minutes: 3

    steps:
      - name: Checkout gh_hdc
        uses: actions/checkout@v6
        with:
          repository: mike12806/gh_hdc
          token: ${{ secrets.GH_HDC_PAT }}
          path: gh_hdc
          fetch-depth: 0

      - name: Connect to Tailscale
        uses: tailscale/github-action@v4
        with:
          oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}
          tags: tag:ci
          hostname: github-runner-nfs-ip-updater
          version: latest

      - name: Install dependencies
        run: |\n          sudo apt-get update -y
          sudo apt-get install -y jq curl python3 python3-pip
          # Install official TrueNAS API client from GitHub
          sudo pip3 install --upgrade git+https://github.com/truenas/api_client.git
          # Verify installation
          python3 -c "import truenas_api_client; print(f'truenas_api_client installed successfully')"

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Set up kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          # Verify kubectl can connect to the cluster
          kubectl cluster-info
          if [ $? -ne 0 ]; then
            echo "Failed to connect to the cluster"
            kubectl config view --minify
            exit 1
          fi

      - name: Get Kubernetes node IPs and Additional IPs
        id: node_ips
        run: |
          # Get Kubernetes node IPs
          KUBE_IPS=$(kubectl get nodes -o json | jq -r '.items[].status.addresses[] | select(.type=="InternalIP") | .address' | sort -u)
          
          # Function to extract IPs from ansible inventory files
          extract_ips() {
            local file="$1"
            if [[ -f "$file" ]]; then
              # Extract IPs from lines that don't start with [ or #, and grab the first field (usually the IP)
              grep -v '^\[' "$file" | grep -v '^#' | awk '{print $1}' | grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+'
            fi
          }
          
          # List all files in inventory directory for debugging
          echo "Listing contents of gh_hdc/ansible/inventory:"
          ls -la gh_hdc/ansible/inventory/

          # Extract IPs from inventory files using correct paths
          echo "Looking for IPs in inventory files..."
          INVENTORY_FILES=(
            "gh_hdc/ansible/inventory/non_docker_lxc"
            "gh_hdc/ansible/inventory/non_kubernetes_ubuntu_vm_and_lxc"
            "gh_hdc/ansible/inventory/proxmox_hosts"
            "gh_hdc/ansible/inventory/pihole_mac_hosts"
            "gh_hdc/ansible/inventory/kubernetes_hosts"
            "gh_hdc/ansible/inventory/mac_hosts"
          )

          INVENTORY_IPS=""
          for file in "${INVENTORY_FILES[@]}"; do
            echo "Processing file: $file"
            if [[ -f "$file" ]]; then
              echo "Found file: $file"
              echo "File contents:"
              cat "$file" || echo "Failed to read file"
              
              file_ips=$(extract_ips "$file")
              if [[ -n "$file_ips" ]]; then
                echo "IPs found in $file:"
                echo "$file_ips"
                INVENTORY_IPS+="$file_ips"$'\n'
              else
                echo "No IPs found in $file"
              fi
            else
              echo "File not found: $file"
            fi
          done

          # Clean up and deduplicate inventory IPs
          INVENTORY_IPS=$(echo "$INVENTORY_IPS" | sort -u | grep -v '^$')

          echo "Kubernetes IPs:"
          echo "$KUBE_IPS"
          echo "Inventory IPs:"
          echo "$INVENTORY_IPS"
          
          # Combine, filter empty values, and deduplicate all IPs
          ALL_IPS=$(echo -e "${KUBE_IPS}\n${INVENTORY_IPS}" | grep -v '^[[:space:]]*$' | sort -u | tr '\n' ',' | sed 's/,$//')
          
          echo "Combined IPs: $ALL_IPS"
          echo "ips=$ALL_IPS" >> $GITHUB_OUTPUT

      - name: Create TrueNAS API helper script
        run: |
          cat > /tmp/truenas_api.py << 'PYEOF'
          #!/usr/bin/env python3
          """Simple wrapper around truenas_api_client for shell usage"""
          import json
          import sys
          from truenas_api_client import Client

          if __name__ == "__main__":
              if len(sys.argv) < 4:
                  print("Usage: truenas_api.py <uri> <api_key> <method> [params_json]", file=sys.stderr)
                  sys.exit(1)
              
              uri = sys.argv[1]
              api_key = sys.argv[2]
              method = sys.argv[3]
              params = json.loads(sys.argv[4]) if len(sys.argv) > 4 else []
              
              try:
                  with Client(uri=uri) as c:
                      # Authenticate with API key
                      if not c.call("auth.login_with_api_key", api_key):
                          print(json.dumps({"error": "Authentication failed - invalid API key"}))
                          sys.exit(1)
                      
                      # Make the API call
                      result = c.call(method, *params)
                      print(json.dumps({"jsonrpc": "2.0", "result": result, "id": 1}))
              except Exception as e:
                  print(json.dumps({"error": str(e)}), file=sys.stderr)
                  sys.exit(1)
          PYEOF
          
          chmod +x /tmp/truenas_api.py

      - name: Get all NFS share IDs from TrueNAS
        id: get_share_ids
        run: |
          # Get NFS shares from TrueNAS API
          # Convert HTTP(S) URL to WebSocket URI with /api/current endpoint
          API_URI="${{ secrets.TRUENAS_API_URL }}"
          API_URI="${API_URI/http:/ws:}"
          API_URI="${API_URI/https:/wss:}"
          API_URI="${API_URI}/api/current"
          
          API_KEY="${{ secrets.TRUENAS_API_KEY }}"
          
          echo "Connecting to: $API_URI"
          
          # Call TrueNAS API using official client
          RESPONSE=$(python3 /tmp/truenas_api.py "$API_URI" "$API_KEY" "sharing.nfs.query" "[]")
          
          echo "Response received"
          echo "Raw response length: ${#RESPONSE}"
          echo "First 200 chars: ${RESPONSE:0:200}"
          
          # Check if response is valid JSON
          if ! echo "$RESPONSE" | jq -e . >/dev/null 2>&1; then
            echo "Error: Invalid JSON response"
            echo "Full response: $RESPONSE"
            exit 1
          fi
          
          # Check for JSON-RPC error
          if echo "$RESPONSE" | jq -e '.error' >/dev/null 2>&1; then
            echo "JSON-RPC Error:"
            echo "$RESPONSE" | jq '.error'
            exit 1
          fi
          
          # Parse share IDs from JSON-RPC response (result field contains the array)
          SHARE_IDS=$(echo "$RESPONSE" | jq -r '.result[].id' | paste -sd, -)
          if [[ -z "$SHARE_IDS" ]]; then
            echo "No NFS shares found"
            echo "Response: $RESPONSE"
            exit 1
          fi
          echo "share_ids=$SHARE_IDS" >> $GITHUB_OUTPUT
          echo "Found NFS share IDs: $SHARE_IDS"

      - name: Patch NFS shares with new IPs
        run: |
          # Convert HTTP(S) URL to WebSocket URI with /api/current endpoint
          API_URI="${{ secrets.TRUENAS_API_URL }}"
          API_URI="${API_URI/http:/ws:}"
          API_URI="${API_URI/https:/wss:}"
          API_URI="${API_URI}/api/current"
          
          API_KEY="${{ secrets.TRUENAS_API_KEY }}"
          
          # Parse comma-separated lists into arrays
          IFS=',' read -ra IDS <<< "${{ steps.get_share_ids.outputs.share_ids }}"
          IFS=',' read -ra IPS <<< "${{ steps.node_ips.outputs.ips }}"

          for ID in "${IDS[@]}"; do
            # Skip empty IDs
            [[ -z "$ID" ]] && continue

            echo "Processing NFS share ID: $ID"

            # Get current share configuration using official client
            echo "Getting config for share $ID"
            SHARE_RESPONSE=$(python3 /tmp/truenas_api.py "$API_URI" "$API_KEY" "sharing.nfs.get_instance" "[${ID}]")
            
            # Validate the share configuration
            if ! echo "$SHARE_RESPONSE" | jq -e . >/dev/null 2>&1; then
              echo "Error: Invalid JSON response for share $ID"
              echo "Response: $SHARE_RESPONSE"
              exit 1
            fi
            
            # Check for JSON-RPC error
            if echo "$SHARE_RESPONSE" | jq -e '.error' >/dev/null 2>&1; then
              echo "JSON-RPC Error getting share $ID:"
              echo "$SHARE_RESPONSE" | jq '.error'
              exit 1
            fi
            
            # Extract share config from result
            SHARE_CONFIG=$(echo "$SHARE_RESPONSE" | jq -r '.result')

            # Extract path from config (handles both 'path' and 'paths' fields)
            PATHS=$(echo "$SHARE_CONFIG" | jq -r 'if has("paths") then .paths[] else .path end')
            if [[ -z "$PATHS" ]]; then
              echo "Error: No path found in share configuration for ID $ID"
              echo "Config: $SHARE_CONFIG"
              exit 1
            fi
            
            # Format the hosts array with plain IPs, filtering out empty values
            HOSTS_JSON="["
            for IP in "${IPS[@]}"; do
              if [[ -n "$IP" ]]; then
                HOSTS_JSON+="\"$IP\","
              fi
            done
            HOSTS_JSON=${HOSTS_JSON%,}
            HOSTS_JSON+="]"
            
            echo "Updating NFS share ID: $ID with IPs: $HOSTS_JSON"
            
            # Create update data payload
            UPDATE_DATA=$(jq -n \
              --arg path "$PATHS" \
              --argjson hosts "$HOSTS_JSON" \
              '{
                "path": $path,
                "hosts": $hosts,
                "enabled": true
              }')

            # Call update via Python helper
            # Prepare params as JSON array: [id, update_data]
            UPDATE_PARAMS=$(jq -n --argjson id "$ID" --argjson data "$UPDATE_DATA" '[$id, $data]')
            
            echo "Sending update request for share $ID"
            UPDATE_RESPONSE=$(python3 /tmp/truenas_api.py "$API_URI" "$API_KEY" "sharing.nfs.update" "$UPDATE_PARAMS")
            
            # Validate response
            if ! echo "$UPDATE_RESPONSE" | jq -e . >/dev/null 2>&1; then
              echo "Error: Invalid JSON response updating share $ID"
              echo "Response: $UPDATE_RESPONSE"
              exit 1
            fi
            
            # Check for JSON-RPC error
            if echo "$UPDATE_RESPONSE" | jq -e '.error' >/dev/null 2>&1; then
              echo "JSON-RPC Error updating share $ID:"
              echo "$UPDATE_RESPONSE" | jq '.error'
              exit 1
            fi

            echo "Successfully updated NFS share ID: $ID"
          done
