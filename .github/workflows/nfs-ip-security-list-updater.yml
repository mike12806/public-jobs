name: Update TrueNAS NFS Client IPs

on:
  workflow_dispatch:
  schedule:
    - cron: '*/15 * * * *'  # every 15 minutes

concurrency:
  group: nfs-ip-security-list-updater
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  update-nfs-clients:
    runs-on: ubuntu-latest
    timeout-minutes: 3

    steps:
      - name: Checkout gh_hdc
        uses: actions/checkout@v6
        with:
          repository: mike12806/gh_hdc
          token: ${{ secrets.GH_HDC_PAT }}
          path: gh_hdc
          fetch-depth: 0

      - name: Connect to Tailscale
        uses: tailscale/github-action@v4
        with:
          oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}
          tags: tag:ci
          hostname: github-runner-nfs-ip-updater
          version: latest

      - name: Install dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl python3 python3-pip
          # Install Python websocket client (upgrade to latest version for extra_headers support)
          # Use sudo to install system-wide, ensuring it's available to python3
          sudo pip3 install --upgrade websockets
          # Install websocat for WebSocket communication (backup)
          wget -qO /tmp/websocat https://github.com/vi/websocat/releases/download/v1.13.0/websocat.x86_64-unknown-linux-musl
          chmod +x /tmp/websocat
          sudo mv /tmp/websocat /usr/local/bin/websocat

      - name: Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: 'latest'

      - name: Set up kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config
          # Verify kubectl can connect to the cluster
          kubectl cluster-info
          if [ $? -ne 0 ]; then
            echo "Failed to connect to the cluster"
            kubectl config view --minify
            exit 1
          fi

      - name: Get Kubernetes node IPs and Additional IPs
        id: node_ips
        run: |
          # Get Kubernetes node IPs
          KUBE_IPS=$(kubectl get nodes -o json | jq -r '.items[].status.addresses[] | select(.type=="InternalIP") | .address' | sort -u)
          
          # Function to extract IPs from ansible inventory files
          extract_ips() {
            local file="$1"
            if [[ -f "$file" ]]; then
              # Extract IPs from lines that don't start with [ or #, and grab the first field (usually the IP)
              grep -v '^\[' "$file" | grep -v '^#' | awk '{print $1}' | grep -oE '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+'
            fi
          }
          
          # List all files in inventory directory for debugging
          echo "Listing contents of gh_hdc/ansible/inventory:"
          ls -la gh_hdc/ansible/inventory/

          # Extract IPs from inventory files using correct paths
          echo "Looking for IPs in inventory files..."
          INVENTORY_FILES=(
            "gh_hdc/ansible/inventory/non_docker_lxc"
            "gh_hdc/ansible/inventory/non_kubernetes_ubuntu_vm_and_lxc"
            "gh_hdc/ansible/inventory/proxmox_hosts"
            "gh_hdc/ansible/inventory/pihole_mac_hosts"
            "gh_hdc/ansible/inventory/kubernetes_hosts"
            "gh_hdc/ansible/inventory/mac_hosts"
          )

          INVENTORY_IPS=""
          for file in "${INVENTORY_FILES[@]}"; do
            echo "Processing file: $file"
            if [[ -f "$file" ]]; then
              echo "Found file: $file"
              echo "File contents:"
              cat "$file" || echo "Failed to read file"
              
              file_ips=$(extract_ips "$file")
              if [[ -n "$file_ips" ]]; then
                echo "IPs found in $file:"
                echo "$file_ips"
                INVENTORY_IPS+="$file_ips"$'\n'
              else
                echo "No IPs found in $file"
              fi
            else
              echo "File not found: $file"
            fi
          done

          # Clean up and deduplicate inventory IPs
          INVENTORY_IPS=$(echo "$INVENTORY_IPS" | sort -u | grep -v '^$')

          echo "Kubernetes IPs:"
          echo "$KUBE_IPS"
          echo "Inventory IPs:"
          echo "$INVENTORY_IPS"
          
          # Combine, filter empty values, and deduplicate all IPs
          ALL_IPS=$(echo -e "${KUBE_IPS}\n${INVENTORY_IPS}" | grep -v '^[[:space:]]*$' | sort -u | tr '\n' ',' | sed 's/,$//')
          
          echo "Combined IPs: $ALL_IPS"
          echo "ips=$ALL_IPS" >> $GITHUB_OUTPUT

      - name: Create TrueNAS WebSocket helper script
        run: |
          cat > /tmp/truenas_ws.py << 'PYEOF'
          #!/usr/bin/env python3
          import asyncio
          import websockets
          import json
          import sys

          async def truenas_call(url, token, method, params):
              """Call TrueNAS API via WebSocket with proper authentication"""
              try:
                  async with websockets.connect(url, extra_headers={"Authorization": f"Bearer {token}"}) as websocket:
                      # Send JSON-RPC request
                      request = {
                          "jsonrpc": "2.0",
                          "method": method,
                          "params": params,
                          "id": "api-call-1"
                      }
                      
                      await websocket.send(json.dumps(request))
                      
                      # Receive response
                      response = await websocket.recv()
                      return response
                      
              except Exception as e:
                  print(f"Error: {e}", file=sys.stderr)
                  return json.dumps({"error": str(e)})

          if __name__ == "__main__":
              if len(sys.argv) < 4:
                  print("Usage: truenas_ws.py <ws_url> <token> <method> [params_json]", file=sys.stderr)
                  sys.exit(1)
              
              url = sys.argv[1]
              token = sys.argv[2]
              method = sys.argv[3]
              params = json.loads(sys.argv[4]) if len(sys.argv) > 4 else []
              
              response = asyncio.run(truenas_call(url, token, method, params))
              print(response)
          PYEOF
          
          chmod +x /tmp/truenas_ws.py

      - name: Get all NFS share IDs from TrueNAS
        id: get_share_ids
        run: |
          # Get NFS shares from TrueNAS JSON-RPC API over WebSocket
          # Convert HTTP(S) URL to WebSocket URL
          WS_URL="${{ secrets.TRUENAS_API_URL }}"
          WS_URL="${WS_URL/http:/ws:}"
          WS_URL="${WS_URL/https:/wss:}"
          WS_URL="${WS_URL}/websocket"
          
          API_KEY="${{ secrets.TRUENAS_API_KEY }}"
          
          echo "Connecting to WebSocket: $WS_URL"
          
          # Call TrueNAS API using Python helper
          RESPONSE=$(python3 /tmp/truenas_ws.py "$WS_URL" "$API_KEY" "sharing.nfs.query" "[]" 2>&1)
          
          echo "Response received"
          
          # Check if response is valid JSON
          if ! echo "$RESPONSE" | jq -e . >/dev/null 2>&1; then
            echo "Error: Invalid JSON response"
            echo "Response: $RESPONSE"
            exit 1
          fi
          
          # Check for JSON-RPC error
          if echo "$RESPONSE" | jq -e '.error' >/dev/null 2>&1; then
            echo "JSON-RPC Error:"
            echo "$RESPONSE" | jq '.error'
            exit 1
          fi
          
          # Parse share IDs from JSON-RPC response (result field contains the array)
          SHARE_IDS=$(echo "$RESPONSE" | jq -r '.result[].id' | paste -sd, -)
          if [[ -z "$SHARE_IDS" ]]; then
            echo "No NFS shares found"
            echo "Response: $RESPONSE"
            exit 1
          fi
          echo "share_ids=$SHARE_IDS" >> $GITHUB_OUTPUT
          echo "Found NFS share IDs: $SHARE_IDS"

      - name: Patch NFS shares with new IPs
        run: |
          # Convert HTTP(S) URL to WebSocket URL
          WS_URL="${{ secrets.TRUENAS_API_URL }}"
          WS_URL="${WS_URL/http:/ws:}"
          WS_URL="${WS_URL/https:/wss:}"
          WS_URL="${WS_URL}/websocket"
          
          API_KEY="${{ secrets.TRUENAS_API_KEY }}"
          
          # Parse comma-separated lists into arrays
          IFS=',' read -ra IDS <<< "${{ steps.get_share_ids.outputs.share_ids }}"
          IFS=',' read -ra IPS <<< "${{ steps.node_ips.outputs.ips }}"

          for ID in "${IDS[@]}"; do
            # Skip empty IDs
            [[ -z "$ID" ]] && continue

            echo "Processing NFS share ID: $ID"

            # Get current share configuration using Python helper
            echo "Getting config for share $ID"
            SHARE_RESPONSE=$(python3 /tmp/truenas_ws.py "$WS_URL" "$API_KEY" "sharing.nfs.get_instance" "[${ID}]" 2>&1)
            
            # Validate the share configuration
            if ! echo "$SHARE_RESPONSE" | jq -e . >/dev/null 2>&1; then
              echo "Error: Invalid JSON response for share $ID"
              echo "Response: $SHARE_RESPONSE"
              exit 1
            fi
            
            # Check for JSON-RPC error
            if echo "$SHARE_RESPONSE" | jq -e '.error' >/dev/null 2>&1; then
              echo "JSON-RPC Error getting share $ID:"
              echo "$SHARE_RESPONSE" | jq '.error'
              exit 1
            fi
            
            # Extract share config from result
            SHARE_CONFIG=$(echo "$SHARE_RESPONSE" | jq -r '.result')

            # Extract path from config (handles both 'path' and 'paths' fields)
            PATHS=$(echo "$SHARE_CONFIG" | jq -r 'if has("paths") then .paths[] else .path end')
            if [[ -z "$PATHS" ]]; then
              echo "Error: No path found in share configuration for ID $ID"
              echo "Config: $SHARE_CONFIG"
              exit 1
            fi
            
            # Format the hosts array with plain IPs, filtering out empty values
            HOSTS_JSON="["
            for IP in "${IPS[@]}"; do
              if [[ -n "$IP" ]]; then
                HOSTS_JSON+="\"$IP\","
              fi
            done
            HOSTS_JSON=${HOSTS_JSON%,}
            HOSTS_JSON+="]"
            
            echo "Updating NFS share ID: $ID with IPs: $HOSTS_JSON"
            
            # Create update data payload
            UPDATE_DATA=$(jq -n \
              --arg path "$PATHS" \
              --argjson hosts "$HOSTS_JSON" \
              '{
                "path": $path,
                "hosts": $hosts,
                "enabled": true
              }')

            # Call update via Python helper
            # Prepare params as JSON array: [id, update_data]
            UPDATE_PARAMS=$(jq -n --argjson id "$ID" --argjson data "$UPDATE_DATA" '[$id, $data]')
            
            echo "Sending update request for share $ID"
            UPDATE_RESPONSE=$(python3 /tmp/truenas_ws.py "$WS_URL" "$API_KEY" "sharing.nfs.update" "$UPDATE_PARAMS" 2>&1)
            
            # Validate response
            if ! echo "$UPDATE_RESPONSE" | jq -e . >/dev/null 2>&1; then
              echo "Error: Invalid JSON response updating share $ID"
              echo "Response: $UPDATE_RESPONSE"
              exit 1
            fi
            
            # Check for JSON-RPC error
            if echo "$UPDATE_RESPONSE" | jq -e '.error' >/dev/null 2>&1; then
              echo "JSON-RPC Error updating share $ID:"
              echo "$UPDATE_RESPONSE" | jq '.error'
              exit 1
            fi

            echo "Successfully updated NFS share ID: $ID"
          done
